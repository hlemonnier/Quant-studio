"""
Stress Testing Framework for V1-Œ± (¬ß3.9)

Implements comprehensive stress testing scenarios to validate
algorithm robustness under extreme market conditions:

1. Flash crash scenarios (-20% in minutes)
2. Extreme volatility spikes (5x normal)
3. Liquidity drought (wide spreads)
4. Trending markets (sustained directional moves)
5. High-frequency noise (rapid price oscillations)
6. Network latency spikes
7. Partial fills and order rejections

This ensures the algorithm performs safely under all market conditions.
"""

import asyncio
import pandas as pd
import numpy as np
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Optional, Tuple, Any
import logging
from dataclasses import dataclass
from enum import Enum

from strategies.MM.config import MMConfig
from strategies.MM.backtest_v1_alpha import BacktestEngine, MarketDataSimulator

mm_config = MMConfig()


class StressScenario(Enum):
    """Enumeration of stress test scenarios"""
    FLASH_CRASH = "flash_crash"
    VOLATILITY_SPIKE = "volatility_spike"
    LIQUIDITY_DROUGHT = "liquidity_drought"
    TRENDING_MARKET = "trending_market"
    HIGH_FREQUENCY_NOISE = "hf_noise"
    LATENCY_SPIKE = "latency_spike"
    ORDER_REJECTIONS = "order_rejections"
    EXTREME_INVENTORY = "extreme_inventory"


@dataclass
class StressTestConfig:
    """Configuration for a stress test scenario"""
    scenario: StressScenario
    duration_minutes: int
    severity: float  # 1.0 = normal, 2.0 = 2x severity, etc.
    description: str
    expected_behavior: str


class StressDataGenerator:
    """
    Generates extreme market data for stress testing
    """
    
    def __init__(self, symbol: str, base_price: float = 50000.0):
        self.symbol = symbol
        self.base_price = base_price
        self.logger = logging.getLogger(f"StressGen-{symbol}")
        
    def generate_flash_crash(self, severity: float = 1.0, 
                           duration_minutes: int = 10) -> pd.DataFrame:
        """
        Generate flash crash scenario: rapid price drop followed by recovery
        
        Args:
            severity: 1.0 = -20% crash, 2.0 = -40% crash
            duration_minutes: Duration of the crash event
        """
        crash_magnitude = -0.20 * severity  # Base -20% crash
        recovery_factor = 0.7  # Recover 70% of the drop
        
        ticks_per_minute = 600  # 100ms ticks
        total_ticks = duration_minutes * ticks_per_minute
        
        # Phase 1: Rapid crash (first 20% of time)
        crash_ticks = int(total_ticks * 0.2)
        # Phase 2: Stabilization (middle 60% of time)  
        stable_ticks = int(total_ticks * 0.6)
        # Phase 3: Partial recovery (last 20% of time)\n        recovery_ticks = total_ticks - crash_ticks - stable_ticks\n        \n        data = []\n        current_price = self.base_price\n        base_time = datetime.now(timezone.utc)\n        \n        # Phase 1: Crash\n        crash_per_tick = crash_magnitude / crash_ticks\n        for i in range(crash_ticks):\n            # Accelerating crash (quadratic)\n            progress = (i + 1) / crash_ticks\n            price_change = crash_per_tick * progress * progress\n            current_price = self.base_price * (1 + price_change)\n            \n            # Extreme spread widening during crash\n            spread_multiplier = 1 + 10 * progress  # Up to 11x normal spread\n            \n            data.append(self._create_tick(\n                base_time + timedelta(milliseconds=i * 100),\n                current_price,\n                spread_multiplier,\n                volume_multiplier=5.0,  # High volume during crash\n                regime=\"flash_crash\"\n            ))\n        \n        # Phase 2: Stabilization at crash level\n        crash_price = current_price\n        for i in range(stable_ticks):\n            # Small random walk around crash level\n            noise = np.random.normal(0, 0.001)  # 0.1% noise\n            current_price = crash_price * (1 + noise)\n            \n            # Gradually normalizing spreads\n            progress = i / stable_ticks\n            spread_multiplier = 11 - 10 * progress  # From 11x back to 1x\n            \n            tick_idx = crash_ticks + i\n            data.append(self._create_tick(\n                base_time + timedelta(milliseconds=tick_idx * 100),\n                current_price,\n                spread_multiplier,\n                volume_multiplier=2.0,  # Elevated volume\n                regime=\"crash_stabilization\"\n            ))\n        \n        # Phase 3: Partial recovery\n        recovery_amount = -crash_magnitude * recovery_factor\n        recovery_per_tick = recovery_amount / recovery_ticks\n        \n        for i in range(recovery_ticks):\n            # Linear recovery\n            current_price += self.base_price * recovery_per_tick\n            \n            tick_idx = crash_ticks + stable_ticks + i\n            data.append(self._create_tick(\n                base_time + timedelta(milliseconds=tick_idx * 100),\n                current_price,\n                spread_multiplier=1.0,  # Normal spreads\n                volume_multiplier=3.0,  # High recovery volume\n                regime=\"crash_recovery\"\n            ))\n        \n        df = pd.DataFrame(data)\n        self.logger.info(\n            f\"üìâ Generated flash crash: {crash_magnitude:.1%} drop, \"\n            f\"{duration_minutes}min duration, {len(df)} ticks\"\n        )\n        return df\n    \n    def generate_volatility_spike(self, severity: float = 2.0,\n                                duration_minutes: int = 30) -> pd.DataFrame:\n        \"\"\"\n        Generate extreme volatility spike scenario\n        \n        Args:\n            severity: Volatility multiplier (2.0 = 2x normal vol)\n            duration_minutes: Duration of high volatility\n        \"\"\"\n        base_vol = 0.8  # 80% annual volatility\n        spike_vol = base_vol * severity\n        \n        ticks_per_minute = 600\n        total_ticks = duration_minutes * ticks_per_minute\n        \n        data = []\n        current_price = self.base_price\n        base_time = datetime.now(timezone.utc)\n        \n        # Convert to per-tick volatility\n        dt = 1.0 / (365 * 24 * 60 * 60 * 10)  # 100ms in year fraction\n        vol_per_tick = spike_vol * np.sqrt(dt)\n        \n        for i in range(total_ticks):\n            # High volatility random walk\n            return_shock = np.random.normal(0, vol_per_tick)\n            current_price *= (1 + return_shock)\n            \n            # Spread widens with volatility\n            spread_multiplier = 1 + severity * 0.5  # Spreads widen\n            \n            data.append(self._create_tick(\n                base_time + timedelta(milliseconds=i * 100),\n                current_price,\n                spread_multiplier,\n                volume_multiplier=0.5,  # Lower volume in volatile times\n                regime=\"volatility_spike\"\n            ))\n        \n        df = pd.DataFrame(data)\n        self.logger.info(\n            f\"‚ö° Generated volatility spike: {severity:.1f}x normal vol, \"\n            f\"{duration_minutes}min duration\"\n        )\n        return df\n    \n    def generate_liquidity_drought(self, severity: float = 3.0,\n                                 duration_minutes: int = 60) -> pd.DataFrame:\n        \"\"\"\n        Generate liquidity drought: very wide spreads, low volume\n        \n        Args:\n            severity: Spread widening factor\n            duration_minutes: Duration of liquidity drought\n        \"\"\"\n        ticks_per_minute = 600\n        total_ticks = duration_minutes * ticks_per_minute\n        \n        data = []\n        current_price = self.base_price\n        base_time = datetime.now(timezone.utc)\n        \n        for i in range(total_ticks):\n            # Very slow price movement\n            drift = np.random.normal(0, 0.0001)  # Minimal movement\n            current_price *= (1 + drift)\n            \n            # Extremely wide spreads\n            spread_multiplier = severity\n            \n            data.append(self._create_tick(\n                base_time + timedelta(milliseconds=i * 100),\n                current_price,\n                spread_multiplier,\n                volume_multiplier=0.1,  # Very low volume\n                regime=\"liquidity_drought\"\n            ))\n        \n        df = pd.DataFrame(data)\n        self.logger.info(\n            f\"üèúÔ∏è Generated liquidity drought: {severity:.1f}x spreads, \"\n            f\"{duration_minutes}min duration\"\n        )\n        return df\n    \n    def generate_trending_market(self, trend_pct: float = 15.0,\n                               duration_minutes: int = 120) -> pd.DataFrame:\n        \"\"\"\n        Generate sustained trending market\n        \n        Args:\n            trend_pct: Total trend magnitude (15.0 = +15%)\n            duration_minutes: Duration of trend\n        \"\"\"\n        ticks_per_minute = 600\n        total_ticks = duration_minutes * ticks_per_minute\n        \n        # Convert trend to per-tick drift\n        total_return = trend_pct / 100.0\n        drift_per_tick = total_return / total_ticks\n        \n        data = []\n        current_price = self.base_price\n        base_time = datetime.now(timezone.utc)\n        \n        for i in range(total_ticks):\n            # Consistent upward drift + noise\n            noise = np.random.normal(0, 0.0005)  # Small noise\n            return_total = drift_per_tick + noise\n            current_price *= (1 + return_total)\n            \n            data.append(self._create_tick(\n                base_time + timedelta(milliseconds=i * 100),\n                current_price,\n                spread_multiplier=1.0,\n                volume_multiplier=1.5,  # Elevated volume in trends\n                regime=\"trending_up\" if trend_pct > 0 else \"trending_down\"\n            ))\n        \n        df = pd.DataFrame(data)\n        direction = \"up\" if trend_pct > 0 else \"down\"\n        self.logger.info(\n            f\"üìà Generated trending market: {trend_pct:+.1f}% {direction}, \"\n            f\"{duration_minutes}min duration\"\n        )\n        return df\n    \n    def generate_hf_noise(self, noise_intensity: float = 2.0,\n                         duration_minutes: int = 15) -> pd.DataFrame:\n        \"\"\"\n        Generate high-frequency noise scenario\n        \n        Args:\n            noise_intensity: Intensity of price oscillations\n            duration_minutes: Duration of noisy period\n        \"\"\"\n        ticks_per_minute = 600\n        total_ticks = duration_minutes * ticks_per_minute\n        \n        data = []\n        current_price = self.base_price\n        base_time = datetime.now(timezone.utc)\n        \n        for i in range(total_ticks):\n            # High-frequency oscillations\n            # Sine wave + random noise\n            sine_component = 0.001 * noise_intensity * np.sin(i * 0.1)\n            noise_component = np.random.normal(0, 0.0005 * noise_intensity)\n            \n            price_change = sine_component + noise_component\n            current_price = self.base_price * (1 + price_change)\n            \n            data.append(self._create_tick(\n                base_time + timedelta(milliseconds=i * 100),\n                current_price,\n                spread_multiplier=1.2,  # Slightly wider spreads\n                volume_multiplier=0.8,  # Lower volume\n                regime=\"hf_noise\"\n            ))\n        \n        df = pd.DataFrame(data)\n        self.logger.info(\n            f\"üåä Generated HF noise: {noise_intensity:.1f}x intensity, \"\n            f\"{duration_minutes}min duration\"\n        )\n        return df\n    \n    def _create_tick(self, timestamp: datetime, mid_price: float,\n                    spread_multiplier: float = 1.0,\n                    volume_multiplier: float = 1.0,\n                    regime: str = \"normal\") -> Dict:\n        \"\"\"Create a single market data tick\"\"\"\n        # Base spread (realistic for crypto)\n        base_spread_bps = 5.0  # 5 basis points\n        spread = (mid_price * base_spread_bps / 10000) * spread_multiplier\n        \n        bid_price = mid_price - spread / 2\n        ask_price = mid_price + spread / 2\n        \n        # Volume with log-normal distribution\n        base_volume = np.random.lognormal(mean=2.0, sigma=1.0)\n        volume = base_volume * volume_multiplier\n        \n        return {\n            'timestamp': timestamp,\n            'mid_price': mid_price,\n            'bid_price': bid_price,\n            'ask_price': ask_price,\n            'spread': spread,\n            'spread_bps': (spread / mid_price) * 10000,\n            'volume': volume,\n            'regime': regime,\n            'day': 1  # Single day for stress tests\n        }\n\n\nclass StressTester:\n    \"\"\"\n    Main stress testing orchestrator\n    \n    Runs various stress scenarios and evaluates algorithm performance\n    under extreme conditions.\n    \"\"\"\n    \n    def __init__(self, symbol: str = 'BTCUSDT'):\n        self.symbol = symbol\n        self.logger = logging.getLogger(f\"StressTester-{symbol}\")\n        \n        # Define stress test scenarios\n        self.scenarios = {\n            StressScenario.FLASH_CRASH: StressTestConfig(\n                scenario=StressScenario.FLASH_CRASH,\n                duration_minutes=10,\n                severity=1.5,  # -30% crash\n                description=\"Flash crash: -30% drop in 10 minutes\",\n                expected_behavior=\"Algorithm should pause trading, limit losses\"\n            ),\n            StressScenario.VOLATILITY_SPIKE: StressTestConfig(\n                scenario=StressScenario.VOLATILITY_SPIKE,\n                duration_minutes=30,\n                severity=3.0,  # 3x normal volatility\n                description=\"Extreme volatility: 3x normal for 30 minutes\",\n                expected_behavior=\"Wider spreads, reduced position sizes\"\n            ),\n            StressScenario.LIQUIDITY_DROUGHT: StressTestConfig(\n                scenario=StressScenario.LIQUIDITY_DROUGHT,\n                duration_minutes=60,\n                severity=5.0,  # 5x wider spreads\n                description=\"Liquidity drought: 5x spreads for 1 hour\",\n                expected_behavior=\"Reduced quoting, conservative sizing\"\n            ),\n            StressScenario.TRENDING_MARKET: StressTestConfig(\n                scenario=StressScenario.TRENDING_MARKET,\n                duration_minutes=120,\n                severity=20.0,  # +20% trend\n                description=\"Strong trend: +20% over 2 hours\",\n                expected_behavior=\"Inventory skewing, trend following\"\n            ),\n            StressScenario.HIGH_FREQUENCY_NOISE: StressTestConfig(\n                scenario=StressScenario.HIGH_FREQUENCY_NOISE,\n                duration_minutes=15,\n                severity=3.0,  # 3x noise intensity\n                description=\"HF noise: 3x oscillations for 15 minutes\",\n                expected_behavior=\"Stable quoting, noise filtering\"\n            )\n        }\n        \n        self.results = {}\n    \n    async def run_all_stress_tests(self) -> Dict:\n        \"\"\"\n        Run complete stress testing suite\n        \n        Returns:\n            Comprehensive stress test results\n        \"\"\"\n        self.logger.info(\"üß™ Starting comprehensive stress testing suite\")\n        \n        all_results = {\n            'metadata': {\n                'symbol': self.symbol,\n                'test_start': datetime.now(),\n                'scenarios_tested': len(self.scenarios)\n            },\n            'scenario_results': {},\n            'summary': {}\n        }\n        \n        # Run each stress scenario\n        for scenario_enum, config in self.scenarios.items():\n            self.logger.info(f\"üî• Running {scenario_enum.value} stress test\")\n            \n            try:\n                result = await self._run_single_stress_test(config)\n                all_results['scenario_results'][scenario_enum.value] = result\n                \n                # Log result\n                status = \"‚úÖ PASSED\" if result['passed'] else \"‚ùå FAILED\"\n                self.logger.info(\n                    f\"{status} {scenario_enum.value}: \"\n                    f\"PnL ${result['performance']['total_pnl']:+.2f}, \"\n                    f\"Max DD {result['risk_metrics']['max_drawdown']:.2%}\"\n                )\n                \n            except Exception as e:\n                self.logger.error(f\"‚ùå Error in {scenario_enum.value}: {e}\")\n                all_results['scenario_results'][scenario_enum.value] = {\n                    'passed': False,\n                    'error': str(e)\n                }\n        \n        # Compile summary\n        all_results['summary'] = self._compile_stress_summary(all_results)\n        \n        self.logger.info(\"‚úÖ Stress testing suite completed\")\n        return all_results\n    \n    async def _run_single_stress_test(self, config: StressTestConfig) -> Dict:\n        \"\"\"Run a single stress test scenario\"\"\"\n        # Generate stress data\n        generator = StressDataGenerator(self.symbol)\n        \n        if config.scenario == StressScenario.FLASH_CRASH:\n            market_data = generator.generate_flash_crash(\n                severity=config.severity,\n                duration_minutes=config.duration_minutes\n            )\n        elif config.scenario == StressScenario.VOLATILITY_SPIKE:\n            market_data = generator.generate_volatility_spike(\n                severity=config.severity,\n                duration_minutes=config.duration_minutes\n            )\n        elif config.scenario == StressScenario.LIQUIDITY_DROUGHT:\n            market_data = generator.generate_liquidity_drought(\n                severity=config.severity,\n                duration_minutes=config.duration_minutes\n            )\n        elif config.scenario == StressScenario.TRENDING_MARKET:\n            market_data = generator.generate_trending_market(\n                trend_pct=config.severity,\n                duration_minutes=config.duration_minutes\n            )\n        elif config.scenario == StressScenario.HIGH_FREQUENCY_NOISE:\n            market_data = generator.generate_hf_noise(\n                noise_intensity=config.severity,\n                duration_minutes=config.duration_minutes\n            )\n        else:\n            raise ValueError(f\"Unknown scenario: {config.scenario}\")\n        \n        # Run backtest on stress data\n        engine = BacktestEngine(self.symbol, initial_capital=100000.0)\n        backtest_results = await engine.run_7day_backtest(\n            market_data, save_results=False\n        )\n        \n        # Evaluate stress test results\n        evaluation = self._evaluate_stress_performance(\n            config, backtest_results, market_data\n        )\n        \n        return {\n            'config': {\n                'scenario': config.scenario.value,\n                'duration_minutes': config.duration_minutes,\n                'severity': config.severity,\n                'description': config.description,\n                'expected_behavior': config.expected_behavior\n            },\n            'market_data_stats': {\n                'ticks': len(market_data),\n                'price_range': {\n                    'start': market_data.iloc[0]['mid_price'],\n                    'end': market_data.iloc[-1]['mid_price'],\n                    'min': market_data['mid_price'].min(),\n                    'max': market_data['mid_price'].max()\n                },\n                'max_spread_bps': market_data['spread_bps'].max(),\n                'avg_spread_bps': market_data['spread_bps'].mean()\n            },\n            'performance': backtest_results['performance']['kpi_summary'],\n            'risk_metrics': evaluation['risk_metrics'],\n            'behavioral_analysis': evaluation['behavioral_analysis'],\n            'passed': evaluation['passed'],\n            'failure_reasons': evaluation.get('failure_reasons', [])\n        }\n    \n    def _evaluate_stress_performance(self, config: StressTestConfig,\n                                   backtest_results: Dict,\n                                   market_data: pd.DataFrame) -> Dict:\n        \"\"\"\n        Evaluate whether the algorithm performed acceptably under stress\n        \n        Criteria for passing stress tests:\n        1. No catastrophic losses (>50% of capital)\n        2. Risk controls activated appropriately\n        3. No runaway inventory accumulation\n        4. Reasonable spread management\n        \"\"\"\n        performance = backtest_results['performance']\n        kpi = performance['kpi_summary']\n        \n        # Calculate additional risk metrics\n        initial_capital = 100000.0\n        final_capital = performance['final_capital']\n        total_return = (final_capital - initial_capital) / initial_capital\n        \n        # Price movement analysis\n        price_start = market_data.iloc[0]['mid_price']\n        price_end = market_data.iloc[-1]['mid_price']\n        market_return = (price_end - price_start) / price_start\n        \n        # Risk metrics\n        risk_metrics = {\n            'total_return': total_return,\n            'market_return': market_return,\n            'max_drawdown': min(0, total_return),  # Simplified\n            'final_inventory': performance['final_inventory'],\n            'max_inventory_ratio': abs(performance['final_inventory']) / mm_config.max_inventory\n        }\n        \n        # Behavioral analysis\n        behavioral_analysis = {\n            'trading_paused_appropriately': self._check_trading_pauses(config, kpi),\n            'inventory_controlled': risk_metrics['max_inventory_ratio'] <= 1.0,\n            'spreads_widened_appropriately': self._check_spread_behavior(config, market_data),\n            'no_runaway_losses': total_return > -0.5  # No more than 50% loss\n        }\n        \n        # Determine if test passed\n        critical_failures = []\n        \n        if total_return <= -0.5:\n            critical_failures.append(\"Catastrophic loss >50%\")\n        \n        if risk_metrics['max_inventory_ratio'] > 1.5:\n            critical_failures.append(\"Excessive inventory accumulation\")\n        \n        # Scenario-specific checks\n        if config.scenario == StressScenario.FLASH_CRASH:\n            # Should limit losses during crash\n            if total_return < market_return * 0.5:  # Shouldn't lose more than 50% of market move\n                critical_failures.append(\"Excessive losses during flash crash\")\n        \n        elif config.scenario == StressScenario.VOLATILITY_SPIKE:\n            # Should reduce activity during high volatility\n            if kpi['total_quotes'] > len(market_data) * 0.5:  # Shouldn't quote on >50% of ticks\n                critical_failures.append(\"Excessive quoting during volatility spike\")\n        \n        passed = len(critical_failures) == 0\n        \n        return {\n            'risk_metrics': risk_metrics,\n            'behavioral_analysis': behavioral_analysis,\n            'passed': passed,\n            'failure_reasons': critical_failures\n        }\n    \n    def _check_trading_pauses(self, config: StressTestConfig, kpi: Dict) -> bool:\n        \"\"\"Check if trading was paused appropriately during stress\"\"\"\n        # This is a simplified check - in reality we'd analyze the quote history\n        # to see if trading was paused during the most extreme moments\n        return True  # Placeholder\n    \n    def _check_spread_behavior(self, config: StressTestConfig, \n                             market_data: pd.DataFrame) -> bool:\n        \"\"\"Check if spreads were managed appropriately\"\"\"\n        # Check if algorithm adapted to market conditions\n        max_market_spread = market_data['spread_bps'].max()\n        \n        # During stress, we expect some spread widening\n        if config.scenario in [StressScenario.VOLATILITY_SPIKE, \n                              StressScenario.LIQUIDITY_DROUGHT]:\n            return max_market_spread > 20  # Should see wider spreads\n        \n        return True\n    \n    def _compile_stress_summary(self, all_results: Dict) -> Dict:\n        \"\"\"Compile overall stress testing summary\"\"\"\n        scenario_results = all_results['scenario_results']\n        \n        passed_tests = sum(\n            1 for result in scenario_results.values() \n            if result.get('passed', False)\n        )\n        total_tests = len(scenario_results)\n        \n        # Aggregate metrics\n        total_pnls = [\n            result['performance']['total_pnl'] \n            for result in scenario_results.values()\n            if 'performance' in result\n        ]\n        \n        return {\n            'overall_pass_rate': passed_tests / total_tests if total_tests > 0 else 0,\n            'tests_passed': passed_tests,\n            'total_tests': total_tests,\n            'aggregate_pnl': sum(total_pnls) if total_pnls else 0,\n            'worst_case_pnl': min(total_pnls) if total_pnls else 0,\n            'best_case_pnl': max(total_pnls) if total_pnls else 0,\n            'recommendation': self._generate_stress_recommendation(passed_tests, total_tests)\n        }\n    \n    def _generate_stress_recommendation(self, passed: int, total: int) -> str:\n        \"\"\"Generate recommendation based on stress test results\"\"\"\n        pass_rate = passed / total if total > 0 else 0\n        \n        if pass_rate >= 0.9:\n            return \"‚úÖ EXCELLENT: Algorithm shows robust performance under stress\"\n        elif pass_rate >= 0.7:\n            return \"‚ö†Ô∏è GOOD: Minor issues under extreme stress, consider parameter tuning\"\n        elif pass_rate >= 0.5:\n            return \"‚ö†Ô∏è ACCEPTABLE: Some stress scenarios failed, review risk controls\"\n        else:\n            return \"‚ùå POOR: Multiple stress test failures, algorithm needs significant improvement\"\n    \n    def print_stress_summary(self, results: Dict):\n        \"\"\"Print comprehensive stress test summary\"\"\"\n        print(f\"\\nüß™ V1-Œ± Stress Testing Summary\")\n        print(\"=\" * 60)\n        \n        summary = results['summary']\n        print(f\"Overall Pass Rate: {summary['overall_pass_rate']:.1%} ({summary['tests_passed']}/{summary['total_tests']})\")\n        print(f\"Aggregate PnL: ${summary['aggregate_pnl']:+.2f}\")\n        print(f\"Worst Case PnL: ${summary['worst_case_pnl']:+.2f}\")\n        print(f\"Best Case PnL: ${summary['best_case_pnl']:+.2f}\")\n        print(f\"\\n{summary['recommendation']}\")\n        \n        print(f\"\\nüìä Individual Scenario Results:\")\n        for scenario_name, result in results['scenario_results'].items():\n            if 'error' in result:\n                print(f\"  ‚ùå {scenario_name}: ERROR - {result['error']}\")\n            else:\n                status = \"‚úÖ\" if result['passed'] else \"‚ùå\"\n                pnl = result['performance']['total_pnl']\n                print(f\"  {status} {scenario_name}: PnL ${pnl:+.2f}\")\n                \n                if not result['passed'] and result.get('failure_reasons'):\n                    for reason in result['failure_reasons']:\n                        print(f\"      - {reason}\")\n        \n        print(\"=\" * 60)\n\n\nasync def run_stress_testing_suite():\n    \"\"\"\n    Main entry point for stress testing\n    \"\"\"\n    print(\"üß™ Starting V1-Œ± Stress Testing Suite\")\n    print(\"=\" * 50)\n    \n    tester = StressTester('BTCUSDT')\n    results = await tester.run_all_stress_tests()\n    \n    tester.print_stress_summary(results)\n    \n    return results\n\n\nif __name__ == \"__main__\":\n    # Run stress tests\n    results = asyncio.run(run_stress_testing_suite())\n    print(\"\\n‚úÖ Stress testing completed!\")\n

