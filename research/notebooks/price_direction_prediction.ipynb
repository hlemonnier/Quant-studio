{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BTC_USD Price Direction Prediciton Indicator\n",
    "\n",
    "In this notebook I am going to try to see if we can find a buying signal using a classifiaction approach to see when the price will go up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"The four most dangerous words in investing are: 'This time it's different'.\"  Sir John Templeton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 - Import Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "pd.set_option('display.max_columns', 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Data cleaning and formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_gaps_with_forward_filling(df, expected_freq):\n",
    "    \"\"\"\n",
    "    Fills gaps in the DataFrame using forward filling, based on the expected frequency.\n",
    "    Ensures 'time_period_start' is in datetime format and 'id' is the index.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to be forward filled.\n",
    "        expected_freq (str): The frequency string indicating the expected interval between rows.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The interpolated DataFrame with gaps filled.\n",
    "    \"\"\"\n",
    "    # Ensure 'time_period_start' is in datetime format\n",
    "    df['time_period_start'] = pd.to_datetime(df['time_period_start'], utc=True)\n",
    "    \n",
    "    # Temporarily set 'time_period_start' as the index for interpolation\n",
    "    df_temp = df.set_index('time_period_start')\n",
    "    \n",
    "    # Adjust frequency string to pandas-compatible format\n",
    "    expected_freq = expected_freq.replace('HRS', 'h').replace('MIN', 'min')\n",
    "    \n",
    "    # Generate the complete DateTime index based on the expected frequency\n",
    "    full_index = pd.date_range(start=df_temp.index.min(), end=df_temp.index.max(), freq=expected_freq)\n",
    "    \n",
    "    # Reindex the DataFrame to this full index, introducing NaNs for missing timestamps\n",
    "    df_reindexed = df_temp.reindex(full_index)\n",
    "\n",
    "    # Flag rows that are newly introduced by reindexing (contain NaNs)\n",
    "    df_reindexed['is_interpolated'] = df_reindexed.isna().any(axis=1)\n",
    "    \n",
    "    # Perform linear interpolation\n",
    "    df_forward_filled = df_reindexed.interpolate(method='ffill')\n",
    "    \n",
    "    # Move 'time_period_start' back to a column from the index\n",
    "    df_forward_filled.reset_index(inplace=True)\n",
    "    df_forward_filled.rename(columns={'index': 'time_period_start'}, inplace=True)\n",
    "\n",
    "    return df_forward_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43488 entries, 0 to 43487\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   date           43488 non-null  datetime64[ns]\n",
      " 1   price_open     43488 non-null  float64       \n",
      " 2   price_high     43488 non-null  float64       \n",
      " 3   price_low      43488 non-null  float64       \n",
      " 4   price_close    43488 non-null  float64       \n",
      " 5   volume_traded  43488 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(5)\n",
      "memory usage: 2.0 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price_open</th>\n",
       "      <th>price_high</th>\n",
       "      <th>price_low</th>\n",
       "      <th>price_close</th>\n",
       "      <th>volume_traded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-01 00:00:00</td>\n",
       "      <td>23144.37</td>\n",
       "      <td>23183.42</td>\n",
       "      <td>23118.58</td>\n",
       "      <td>23163.47</td>\n",
       "      <td>70.088631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-01 00:15:00</td>\n",
       "      <td>23164.60</td>\n",
       "      <td>23221.87</td>\n",
       "      <td>23161.47</td>\n",
       "      <td>23175.01</td>\n",
       "      <td>91.848881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-01 00:30:00</td>\n",
       "      <td>23175.20</td>\n",
       "      <td>23219.56</td>\n",
       "      <td>23145.00</td>\n",
       "      <td>23147.65</td>\n",
       "      <td>78.157423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-01 00:45:00</td>\n",
       "      <td>23149.44</td>\n",
       "      <td>23151.35</td>\n",
       "      <td>23025.17</td>\n",
       "      <td>23103.31</td>\n",
       "      <td>162.990672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-01 01:00:00</td>\n",
       "      <td>23103.30</td>\n",
       "      <td>23169.00</td>\n",
       "      <td>23077.00</td>\n",
       "      <td>23168.42</td>\n",
       "      <td>103.158688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43483</th>\n",
       "      <td>2024-05-26 22:45:00</td>\n",
       "      <td>68631.21</td>\n",
       "      <td>68632.02</td>\n",
       "      <td>68526.05</td>\n",
       "      <td>68526.05</td>\n",
       "      <td>40.858640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43484</th>\n",
       "      <td>2024-05-26 23:00:00</td>\n",
       "      <td>68526.06</td>\n",
       "      <td>68536.44</td>\n",
       "      <td>68459.28</td>\n",
       "      <td>68468.49</td>\n",
       "      <td>14.352608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43485</th>\n",
       "      <td>2024-05-26 23:15:00</td>\n",
       "      <td>68465.98</td>\n",
       "      <td>68485.60</td>\n",
       "      <td>68323.29</td>\n",
       "      <td>68380.00</td>\n",
       "      <td>18.821390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43486</th>\n",
       "      <td>2024-05-26 23:30:00</td>\n",
       "      <td>68380.00</td>\n",
       "      <td>68470.35</td>\n",
       "      <td>68307.26</td>\n",
       "      <td>68447.71</td>\n",
       "      <td>32.678318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43487</th>\n",
       "      <td>2024-05-26 23:45:00</td>\n",
       "      <td>68446.48</td>\n",
       "      <td>68541.02</td>\n",
       "      <td>68441.96</td>\n",
       "      <td>68473.72</td>\n",
       "      <td>19.189330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43488 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  price_open  price_high  price_low  price_close  \\\n",
       "0     2023-03-01 00:00:00    23144.37    23183.42   23118.58     23163.47   \n",
       "1     2023-03-01 00:15:00    23164.60    23221.87   23161.47     23175.01   \n",
       "2     2023-03-01 00:30:00    23175.20    23219.56   23145.00     23147.65   \n",
       "3     2023-03-01 00:45:00    23149.44    23151.35   23025.17     23103.31   \n",
       "4     2023-03-01 01:00:00    23103.30    23169.00   23077.00     23168.42   \n",
       "...                   ...         ...         ...        ...          ...   \n",
       "43483 2024-05-26 22:45:00    68631.21    68632.02   68526.05     68526.05   \n",
       "43484 2024-05-26 23:00:00    68526.06    68536.44   68459.28     68468.49   \n",
       "43485 2024-05-26 23:15:00    68465.98    68485.60   68323.29     68380.00   \n",
       "43486 2024-05-26 23:30:00    68380.00    68470.35   68307.26     68447.71   \n",
       "43487 2024-05-26 23:45:00    68446.48    68541.02   68441.96     68473.72   \n",
       "\n",
       "       volume_traded  \n",
       "0          70.088631  \n",
       "1          91.848881  \n",
       "2          78.157423  \n",
       "3         162.990672  \n",
       "4         103.158688  \n",
       "...              ...  \n",
       "43483      40.858640  \n",
       "43484      14.352608  \n",
       "43485      18.821390  \n",
       "43486      32.678318  \n",
       "43487      19.189330  \n",
       "\n",
       "[43488 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/SolalDanan/Trading Signal/1years_ohlcv_btc_usd_spot_15MIN.csv\", parse_dates=['time_period_start'])\n",
    "df = fill_gaps_with_forward_filling(df,'15MIN')\n",
    "df = df[['time_period_start', 'price_open', 'price_high','price_low', 'price_close', 'volume_traded']].rename(columns={'time_period_start': 'date'})\n",
    "df['date'] = df['date'].dt.tz_convert(None)\n",
    "# df.insert(loc=0, column='unique_id', value=1)\n",
    "\n",
    "print(df.info())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date             0\n",
       "price_open       0\n",
       "price_high       0\n",
       "price_low        0\n",
       "price_close      0\n",
       "volume_traded    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Problem formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price_open</th>\n",
       "      <th>price_high</th>\n",
       "      <th>price_low</th>\n",
       "      <th>price_close</th>\n",
       "      <th>volume_traded</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43470</th>\n",
       "      <td>2024-05-26 19:30:00</td>\n",
       "      <td>68801.98</td>\n",
       "      <td>68855.14</td>\n",
       "      <td>68783.96</td>\n",
       "      <td>68848.81</td>\n",
       "      <td>19.788238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43471</th>\n",
       "      <td>2024-05-26 19:45:00</td>\n",
       "      <td>68848.81</td>\n",
       "      <td>68874.47</td>\n",
       "      <td>68801.89</td>\n",
       "      <td>68864.96</td>\n",
       "      <td>11.433655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43472</th>\n",
       "      <td>2024-05-26 20:00:00</td>\n",
       "      <td>68866.83</td>\n",
       "      <td>68873.02</td>\n",
       "      <td>68805.06</td>\n",
       "      <td>68806.77</td>\n",
       "      <td>15.426890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43473</th>\n",
       "      <td>2024-05-26 20:15:00</td>\n",
       "      <td>68806.77</td>\n",
       "      <td>68814.58</td>\n",
       "      <td>68720.00</td>\n",
       "      <td>68737.49</td>\n",
       "      <td>18.508655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43474</th>\n",
       "      <td>2024-05-26 20:30:00</td>\n",
       "      <td>68736.18</td>\n",
       "      <td>68742.63</td>\n",
       "      <td>68660.02</td>\n",
       "      <td>68686.36</td>\n",
       "      <td>24.052207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43475</th>\n",
       "      <td>2024-05-26 20:45:00</td>\n",
       "      <td>68686.36</td>\n",
       "      <td>68700.58</td>\n",
       "      <td>68667.31</td>\n",
       "      <td>68680.91</td>\n",
       "      <td>14.446930</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43476</th>\n",
       "      <td>2024-05-26 21:00:00</td>\n",
       "      <td>68680.91</td>\n",
       "      <td>68680.91</td>\n",
       "      <td>68517.00</td>\n",
       "      <td>68532.73</td>\n",
       "      <td>60.030813</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43477</th>\n",
       "      <td>2024-05-26 21:15:00</td>\n",
       "      <td>68532.74</td>\n",
       "      <td>68613.17</td>\n",
       "      <td>68532.74</td>\n",
       "      <td>68573.01</td>\n",
       "      <td>18.009711</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43478</th>\n",
       "      <td>2024-05-26 21:30:00</td>\n",
       "      <td>68573.01</td>\n",
       "      <td>68573.01</td>\n",
       "      <td>68097.38</td>\n",
       "      <td>68353.41</td>\n",
       "      <td>101.128505</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43479</th>\n",
       "      <td>2024-05-26 21:45:00</td>\n",
       "      <td>68351.50</td>\n",
       "      <td>68510.45</td>\n",
       "      <td>68259.34</td>\n",
       "      <td>68495.63</td>\n",
       "      <td>36.525934</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43480</th>\n",
       "      <td>2024-05-26 22:00:00</td>\n",
       "      <td>68495.63</td>\n",
       "      <td>68581.94</td>\n",
       "      <td>68431.37</td>\n",
       "      <td>68578.68</td>\n",
       "      <td>64.891905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43481</th>\n",
       "      <td>2024-05-26 22:15:00</td>\n",
       "      <td>68579.92</td>\n",
       "      <td>68662.50</td>\n",
       "      <td>68552.50</td>\n",
       "      <td>68643.67</td>\n",
       "      <td>58.775076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43482</th>\n",
       "      <td>2024-05-26 22:30:00</td>\n",
       "      <td>68645.13</td>\n",
       "      <td>68682.44</td>\n",
       "      <td>68598.59</td>\n",
       "      <td>68629.20</td>\n",
       "      <td>28.979680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43483</th>\n",
       "      <td>2024-05-26 22:45:00</td>\n",
       "      <td>68631.21</td>\n",
       "      <td>68632.02</td>\n",
       "      <td>68526.05</td>\n",
       "      <td>68526.05</td>\n",
       "      <td>40.858640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43484</th>\n",
       "      <td>2024-05-26 23:00:00</td>\n",
       "      <td>68526.06</td>\n",
       "      <td>68536.44</td>\n",
       "      <td>68459.28</td>\n",
       "      <td>68468.49</td>\n",
       "      <td>14.352608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  price_open  price_high  price_low  price_close  \\\n",
       "43470 2024-05-26 19:30:00    68801.98    68855.14   68783.96     68848.81   \n",
       "43471 2024-05-26 19:45:00    68848.81    68874.47   68801.89     68864.96   \n",
       "43472 2024-05-26 20:00:00    68866.83    68873.02   68805.06     68806.77   \n",
       "43473 2024-05-26 20:15:00    68806.77    68814.58   68720.00     68737.49   \n",
       "43474 2024-05-26 20:30:00    68736.18    68742.63   68660.02     68686.36   \n",
       "43475 2024-05-26 20:45:00    68686.36    68700.58   68667.31     68680.91   \n",
       "43476 2024-05-26 21:00:00    68680.91    68680.91   68517.00     68532.73   \n",
       "43477 2024-05-26 21:15:00    68532.74    68613.17   68532.74     68573.01   \n",
       "43478 2024-05-26 21:30:00    68573.01    68573.01   68097.38     68353.41   \n",
       "43479 2024-05-26 21:45:00    68351.50    68510.45   68259.34     68495.63   \n",
       "43480 2024-05-26 22:00:00    68495.63    68581.94   68431.37     68578.68   \n",
       "43481 2024-05-26 22:15:00    68579.92    68662.50   68552.50     68643.67   \n",
       "43482 2024-05-26 22:30:00    68645.13    68682.44   68598.59     68629.20   \n",
       "43483 2024-05-26 22:45:00    68631.21    68632.02   68526.05     68526.05   \n",
       "43484 2024-05-26 23:00:00    68526.06    68536.44   68459.28     68468.49   \n",
       "\n",
       "       volume_traded  target  \n",
       "43470      19.788238       0  \n",
       "43471      11.433655       0  \n",
       "43472      15.426890       0  \n",
       "43473      18.508655       0  \n",
       "43474      24.052207       0  \n",
       "43475      14.446930       0  \n",
       "43476      60.030813       0  \n",
       "43477      18.009711       1  \n",
       "43478     101.128505       1  \n",
       "43479      36.525934       1  \n",
       "43480      64.891905       0  \n",
       "43481      58.775076       0  \n",
       "43482      28.979680       0  \n",
       "43483      40.858640       0  \n",
       "43484      14.352608       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0\n",
    "\n",
    "# Creating a target that looks 'forward' in time\n",
    "future_period = 3\n",
    "df['future_price'] = df['price_close'].shift(-future_period)\n",
    "df['price_change'] = df['future_price'] - df['price_close']\n",
    "\n",
    "df['target'] = 0\n",
    "df.loc[df['price_change'] > threshold, 'target'] += 1\n",
    "\n",
    "df.dropna(inplace=True)  # Drop rows with NaN values resulting from shifts\n",
    "df.drop(columns=['price_change', 'future_price'], inplace=True)\n",
    "df.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Exploratory data analysis EDA\n",
    "Let's explore the distribution of numerical features in more detail, including histograms and kernel density estimations, and box plots. We will:\n",
    "\n",
    "- Investigate the relationships between numerical features and the target variable (Cover_Type).\n",
    "- Examine the distribution of categorical features and their impact on the target variable.\n",
    "- Detect and handle any outliers or anomalies in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['target'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "df['target'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No worries about class imbalances during the model training phase.\n",
    "\n",
    "Distribution of class shows perfect uniform distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution and relationship of continuous variables (Elevation, Aspect, Slope, Distance and Hillsahde columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custom_palette = sns.color_palette(\"husl\", 2) \\nprint(df.columns)\\n\\n# Pairplot to visualize relationships between numerical features with custom colors\\nsns.pairplot(df, hue=\\'target\\', diag_kind=\\'kde\\', palette=custom_palette)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''custom_palette = sns.color_palette(\"husl\", 2) \n",
    "print(df.columns)\n",
    "\n",
    "# Pairplot to visualize relationships between numerical features with custom colors\n",
    "sns.pairplot(df, hue='target', diag_kind='kde', palette=custom_palette)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We defintely need some new feature that exibit specific pattern according to the class because here it is not enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Pearson Correlation of Features')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# store continious variables in a list\n",
    "continuous_variables = ['price_close', 'price_high', 'price_low', 'price_open', 'volume_traded', 'volume_traded']\n",
    "\n",
    "# make a list of numeric features and create a dataframe with them\n",
    "train_w_numeric_soil = df[continuous_variables]\n",
    "\n",
    "# pearson coefficients with numeric soil type column\n",
    "correlations = pd.DataFrame(train_w_numeric_soil.corr())\n",
    "\n",
    "figsize=(20,30)\n",
    "sns.set(font_scale=.5)  # Increase font scale for labels\n",
    "\n",
    "# plot the heatmap\n",
    "colormap = plt.cm.RdBu\n",
    "sns.heatmap(correlations,linewidths=0.1,\n",
    "            square=False, cmap=colormap, linecolor='white', annot=True)\n",
    "plt.title('Pearson Correlation of Features', size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price Open, Close, Hifh,, Low are correlated at 1 and exibits the same distribution, we will need ther feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_features = ['price_open', 'price_high', 'price_low', 'price_close', 'volume_traded']\n",
    "new_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price_close_d\"] = df[\"price_close\"] * 2\n",
    "init_features.append('price_close_d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technical Indicators\n",
    "\n",
    "Technical indicators were chosen as part of the feature set because they help reduce noise in candlestick data and may reveal price patterns for the model to learn, if any exist. These particular indicators were chosen to give insight into price momentum, volatility, trends, and whether the cryptocurrency is overbought or oversold:\n",
    "\n",
    "- Rate of Change Ratio (ROCR): Measures the percentage change between the current price and the price a certain number of periods ago.\n",
    "- Average True Range (ATR): Measures market volatility by analyzing the range of price movement in a given period.\n",
    "- On-Balance Volume (OBV): Uses volume flow to predict changes in stock price by comparing the volume during uptrends and downtrends.\n",
    "- Triple Exponential Moving Average (TRIX): Smooths price data and reduces lag by using a triple-smoothed exponential moving average.\n",
    "- Momentum (MOM): Measures the rate of price change over a specified time period.\n",
    "- ADX (Average Directional Index): Measures the strength of the trend but not the direction.\n",
    "- +DI (Positive Directional Indicator, DMP): Measures the presence of an uptrend.\n",
    "- -DI (Negative Directional Indicator, DMN): Measures the presence of a downtrend.\n",
    "- Williams %R (WILLR): Indicates whether a security is overbought or oversold by comparing the close price to the high-low range over a certain period.\n",
    "- Relative Strength Index (RSI): Measures the magnitude of recent price changes to evaluate overbought or oversold conditions.\n",
    "- Moving Average Convergence Divergence (MACD): Shows the relationship between two moving averages of a securityâ€™s price to indicate buy or sell signals.\n",
    "- Exponential Moving Average (EMA): Gives more weight to recent prices to reduce lag and provide a smoothed price trend.\n",
    "\n",
    "Note that, in a perfectly efficient market, the future price of a publicly traded asset is not statistically dependent on past prices; the price follows a \"random walk,\" and it's impossible to reliably leverage technical analysis to beat the market. Now, efficient market theory suggests that the U.S. stock market is at least a semi-efficient market, and so we still consider this feature set because many traders utilize technical analysis in their trading strategies and there may exist a relationship between signals from indicators and executed trades, regardless of whether the signals themselves are accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate technical indicators\n",
    "\n",
    "# Rate of Change Ratio\n",
    "df['ROCR'] = ta.roc(df['price_close'], length=10)  \n",
    "\n",
    "# Average True Range\n",
    "df['ATR'] = ta.atr(df['price_high'], df['price_low'], df['price_close'], length=14)  \n",
    "\n",
    "# On-Balance Volume\n",
    "df['OBV'] = ta.obv(df['price_close'], df['volume_traded'])  \n",
    "\n",
    "# Triple Exponential Moving Average\n",
    "trix = ta.trix(df['price_close'], length=25)  \n",
    "df['TRIX'] = trix['TRIX_25_9']  \n",
    "\n",
    "# Momentum\n",
    "df['MOM'] = ta.mom(df['price_close'], length=10)  \n",
    "\n",
    "# Average Directional Index\n",
    "adx = ta.adx(df['price_high'], df['price_low'], df['price_close'], length=14)  \n",
    "df['ADX'] = adx['ADX_14']\n",
    "df['+DI'] = adx['DMP_14']\n",
    "df['-DI'] = adx['DMN_14']\n",
    "\n",
    "# Williams %R\n",
    "df['WILLR'] = ta.willr(df['price_high'], df['price_low'], df['price_close'], length=14)  \n",
    "\n",
    " # Relative Strength Index\n",
    "df['RSI'] = ta.rsi(df['price_close'], length=14) \n",
    "\n",
    "# Moving Average Convergence Divergence\n",
    "macd = ta.macd(df['price_close'], fast=12, slow=26, signal=9)  \n",
    "df['MACD'] = macd['MACD_12_26_9']\n",
    "\n",
    " # Exponential Moving Average\n",
    "df['EMA'] = ta.ema(df['price_close'], length=30) \n",
    "\n",
    "ta_features.append('RSI')\n",
    "\n",
    "ta_features.append('ATR')\n",
    "ta_features.append('WILLR')\n",
    "\n",
    "\n",
    "ta_features.append('OBV')\n",
    "ta_features.append('TRIX')\n",
    "ta_features.append('MOM')\n",
    "ta_features.append('MACD')\n",
    "\n",
    "ta_features.append('ADX')\n",
    "ta_features.append('+DI')\n",
    "ta_features.append('-DI')\n",
    "ta_features.append('EMA')\n",
    "ta_features.append('ROCR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykalman import KalmanFilter\n",
    "\n",
    "def apply_kalman(series, initial_state, observation_covariance, transition_covariance):\n",
    "    kf = KalmanFilter(initial_state_mean=initial_state, \n",
    "                      observation_covariance=observation_covariance,  # e.g., 1.0\n",
    "                      transition_covariance=transition_covariance)     # e.g., 0.01\n",
    "    state_means, _ = kf.filter(series.values)\n",
    "    return state_means.flatten()\n",
    "\n",
    "# Apply Kalman Filter to the closing prices\n",
    "df['kalman'] = apply_kalman(df['price_close'], initial_state=0, observation_covariance=1.0, transition_covariance=0.01)\n",
    "\n",
    "df['kalman'] = np.sqrt(df['kalman'])\n",
    "\n",
    "\n",
    "ta_features.append('kalman')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Volume & Price Weighted Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of periods to consider for weighted mean\n",
    "n = 4\n",
    "# Create linear weights\n",
    "weights = np.linspace(1, 0, n)\n",
    "\n",
    "# Generate columns for the last n prices and volumes\n",
    "for i in range(1, n + 1):\n",
    "    df[f'price_close_{i}'] = df['price_close'].shift(i)\n",
    "    df[f'volume_traded_{i}'] = df['volume_traded'].shift(i)\n",
    "\n",
    "# Create the weighted mean columns for prices\n",
    "df['weighted_mean_price_close'] = sum(df[f'price_close_{i}'] * weights[i-1] for i in range(1, n + 1)) / weights.sum()\n",
    "\n",
    "# Create the weighted mean columns for volumes\n",
    "df['weighted_mean_volume_traded'] = sum(df[f'volume_traded_{i}'] * weights[i-1] for i in range(1, n + 1)) / weights.sum()\n",
    "\n",
    "# Drop the intermediate columns if not needed\n",
    "for i in range(1, n + 1):\n",
    "    df.drop(columns=[f'price_close_{i}', f'volume_traded_{i}'], inplace=True)\n",
    "\n",
    "\n",
    "new_features.append('weighted_mean_price_close')\n",
    "new_features.append('weighted_mean_volume_traded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blockchain Data  (Idea but need to use an API to scrap some new data)\n",
    "\n",
    "- **Confirmation Time:** Median time for a transaction to be accepted into a block and added to the public ledger. Higher confirmation times might reflect higher demand or slower processing, impacting transaction costs and user behavior.\n",
    "- **Block Size:** Average block size in MB. Larger block sizes can indicate higher transaction volumes, which might correlate with increased network activity and possibly price movements.\n",
    "- **Average Transaction Cost:** Total miner revenue divided by number of transactions. Higher transaction costs could indicate higher network usage, which might correlate with price volatility or trends.\n",
    "- **Difficulty:** Represents mining difficulty, which adjusts to ensure a consistent block production rate. Changes in difficulty could indicate shifts in mining power and potentially affect market sentiment.\n",
    "- **Transaction Value:** Total estimated value of transactions on the blockchain. It might indicate the level of economic activity on the network.\n",
    "- **Hash Rate:** A measure of network security and miner activity. A higher hash rate could indicate a more secure network and greater miner confidence.\n",
    "- **Transactions per Block:** Average number of transactions per block. Reflects network activity. \n",
    "- **Unique Addresses:** A higher number of unique addresses might reflect broader usage and adoption.\n",
    "- **Transaction Fees:** Total value of all transaction fees paid to miners.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regarder le prix ou indicateurs sur un asset corrÃ©ler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Square Root Transformation\n",
    "La transformation par racine carrÃ©e est une technique couramment utilisÃ©e en ingÃ©nierie des caractÃ©ristiques, notamment pour attÃ©nuer les problÃ¨mes posÃ©s par les distributions asymÃ©triques des donnÃ©es. \n",
    "I will perform square root transformation to the features with positive data range. Square root transformation might help especially for the highly skewed distributions. En effet, Square rooot transofrmation, RÃ©duction de l'asymÃ©trie et AmÃ©lioration de la linÃ©aritÃ©\n",
    "\n",
    "We saw earlier that:\n",
    "\n",
    "'ATR' and 'ADX' and 'weighted_mean_volume_traded' left-skewed distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the columns to transform\n",
    "columns_to_transform = ['ATR','ADX', \"weighted_mean_volume_traded\"]\n",
    "\n",
    "# Applying square root transformation only to the specified columns\n",
    "for col in columns_to_transform:\n",
    "    # Adding the transformed columns with a 'sqrt_' prefix\n",
    "    df['sqrt_' + col] =(np.sqrt(df[col]))\n",
    "    new_features.append('sqrt_' + col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"difference1\"]=df[\"price_high\"]-df[\"price_low\"]\n",
    "df[\"difference2\"]=df[\"price_close\"]-df[\"price_open\"]\n",
    "df[\"difference_mean\"] = ((df[\"difference2\"] + df[\"difference1\"]) /2 ) \n",
    "new_features.append('difference_mean')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price_open</th>\n",
       "      <th>price_high</th>\n",
       "      <th>price_low</th>\n",
       "      <th>price_close</th>\n",
       "      <th>volume_traded</th>\n",
       "      <th>target</th>\n",
       "      <th>price_close_d</th>\n",
       "      <th>ROCR</th>\n",
       "      <th>ATR</th>\n",
       "      <th>OBV</th>\n",
       "      <th>TRIX</th>\n",
       "      <th>MOM</th>\n",
       "      <th>ADX</th>\n",
       "      <th>+DI</th>\n",
       "      <th>-DI</th>\n",
       "      <th>WILLR</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>EMA</th>\n",
       "      <th>kalman</th>\n",
       "      <th>weighted_mean_price_close</th>\n",
       "      <th>weighted_mean_volume_traded</th>\n",
       "      <th>sqrt_ATR</th>\n",
       "      <th>sqrt_ADX</th>\n",
       "      <th>sqrt_weighted_mean_volume_traded</th>\n",
       "      <th>difference1</th>\n",
       "      <th>difference2</th>\n",
       "      <th>difference_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023-03-01 07:15:00</td>\n",
       "      <td>23745.52</td>\n",
       "      <td>23758.89</td>\n",
       "      <td>23711.12</td>\n",
       "      <td>23722.99</td>\n",
       "      <td>65.833305</td>\n",
       "      <td>1</td>\n",
       "      <td>47445.98</td>\n",
       "      <td>-0.275469</td>\n",
       "      <td>83.276438</td>\n",
       "      <td>335.401075</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>-65.53</td>\n",
       "      <td>62.288438</td>\n",
       "      <td>34.776171</td>\n",
       "      <td>9.139979</td>\n",
       "      <td>-30.527581</td>\n",
       "      <td>70.203487</td>\n",
       "      <td>175.002457</td>\n",
       "      <td>23458.921333</td>\n",
       "      <td>152.952256</td>\n",
       "      <td>23753.760000</td>\n",
       "      <td>82.567046</td>\n",
       "      <td>9.125592</td>\n",
       "      <td>7.892302</td>\n",
       "      <td>9.086641</td>\n",
       "      <td>47.77</td>\n",
       "      <td>-22.53</td>\n",
       "      <td>12.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023-03-01 07:30:00</td>\n",
       "      <td>23723.00</td>\n",
       "      <td>23735.69</td>\n",
       "      <td>23695.35</td>\n",
       "      <td>23723.00</td>\n",
       "      <td>48.812931</td>\n",
       "      <td>1</td>\n",
       "      <td>47446.00</td>\n",
       "      <td>-0.052664</td>\n",
       "      <td>79.837228</td>\n",
       "      <td>384.214006</td>\n",
       "      <td>0.009480</td>\n",
       "      <td>-12.50</td>\n",
       "      <td>61.326702</td>\n",
       "      <td>33.368683</td>\n",
       "      <td>10.352249</td>\n",
       "      <td>-30.542061</td>\n",
       "      <td>70.204155</td>\n",
       "      <td>165.649568</td>\n",
       "      <td>23475.958667</td>\n",
       "      <td>153.054765</td>\n",
       "      <td>23735.478333</td>\n",
       "      <td>72.409438</td>\n",
       "      <td>8.935168</td>\n",
       "      <td>7.831137</td>\n",
       "      <td>8.509374</td>\n",
       "      <td>40.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023-03-01 07:45:00</td>\n",
       "      <td>23723.01</td>\n",
       "      <td>23733.71</td>\n",
       "      <td>23704.25</td>\n",
       "      <td>23718.30</td>\n",
       "      <td>46.666387</td>\n",
       "      <td>1</td>\n",
       "      <td>47436.60</td>\n",
       "      <td>0.140046</td>\n",
       "      <td>75.836701</td>\n",
       "      <td>337.547619</td>\n",
       "      <td>0.011555</td>\n",
       "      <td>33.17</td>\n",
       "      <td>60.484690</td>\n",
       "      <td>32.339304</td>\n",
       "      <td>10.032896</td>\n",
       "      <td>-34.673407</td>\n",
       "      <td>69.416655</td>\n",
       "      <td>156.059133</td>\n",
       "      <td>23491.593591</td>\n",
       "      <td>153.145906</td>\n",
       "      <td>23726.760000</td>\n",
       "      <td>57.285328</td>\n",
       "      <td>8.708427</td>\n",
       "      <td>7.777190</td>\n",
       "      <td>7.568707</td>\n",
       "      <td>29.46</td>\n",
       "      <td>-4.71</td>\n",
       "      <td>12.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2023-03-01 08:00:00</td>\n",
       "      <td>23716.03</td>\n",
       "      <td>23789.75</td>\n",
       "      <td>23685.96</td>\n",
       "      <td>23769.71</td>\n",
       "      <td>106.761234</td>\n",
       "      <td>1</td>\n",
       "      <td>47539.42</td>\n",
       "      <td>0.360110</td>\n",
       "      <td>78.038932</td>\n",
       "      <td>444.308853</td>\n",
       "      <td>0.013690</td>\n",
       "      <td>85.29</td>\n",
       "      <td>60.324456</td>\n",
       "      <td>34.608222</td>\n",
       "      <td>8.981660</td>\n",
       "      <td>-22.554638</td>\n",
       "      <td>72.986165</td>\n",
       "      <td>150.867890</td>\n",
       "      <td>23509.536586</td>\n",
       "      <td>153.244258</td>\n",
       "      <td>23720.648333</td>\n",
       "      <td>50.576388</td>\n",
       "      <td>8.833965</td>\n",
       "      <td>7.766882</td>\n",
       "      <td>7.111708</td>\n",
       "      <td>103.79</td>\n",
       "      <td>53.68</td>\n",
       "      <td>78.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2023-03-01 08:15:00</td>\n",
       "      <td>23771.09</td>\n",
       "      <td>23788.32</td>\n",
       "      <td>23734.95</td>\n",
       "      <td>23736.19</td>\n",
       "      <td>57.145549</td>\n",
       "      <td>1</td>\n",
       "      <td>47472.38</td>\n",
       "      <td>0.159040</td>\n",
       "      <td>76.109640</td>\n",
       "      <td>387.163304</td>\n",
       "      <td>0.015764</td>\n",
       "      <td>37.69</td>\n",
       "      <td>60.182654</td>\n",
       "      <td>32.710273</td>\n",
       "      <td>8.489097</td>\n",
       "      <td>-47.834752</td>\n",
       "      <td>67.457798</td>\n",
       "      <td>142.407425</td>\n",
       "      <td>23524.159386</td>\n",
       "      <td>153.322722</td>\n",
       "      <td>23744.788333</td>\n",
       "      <td>77.071568</td>\n",
       "      <td>8.724084</td>\n",
       "      <td>7.757748</td>\n",
       "      <td>8.779041</td>\n",
       "      <td>53.37</td>\n",
       "      <td>-34.90</td>\n",
       "      <td>9.235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  price_open  price_high  price_low  price_close  \\\n",
       "29 2023-03-01 07:15:00    23745.52    23758.89   23711.12     23722.99   \n",
       "30 2023-03-01 07:30:00    23723.00    23735.69   23695.35     23723.00   \n",
       "31 2023-03-01 07:45:00    23723.01    23733.71   23704.25     23718.30   \n",
       "32 2023-03-01 08:00:00    23716.03    23789.75   23685.96     23769.71   \n",
       "33 2023-03-01 08:15:00    23771.09    23788.32   23734.95     23736.19   \n",
       "\n",
       "    volume_traded  target  price_close_d      ROCR        ATR         OBV  \\\n",
       "29      65.833305       1       47445.98 -0.275469  83.276438  335.401075   \n",
       "30      48.812931       1       47446.00 -0.052664  79.837228  384.214006   \n",
       "31      46.666387       1       47436.60  0.140046  75.836701  337.547619   \n",
       "32     106.761234       1       47539.42  0.360110  78.038932  444.308853   \n",
       "33      57.145549       1       47472.38  0.159040  76.109640  387.163304   \n",
       "\n",
       "        TRIX    MOM        ADX        +DI        -DI      WILLR        RSI  \\\n",
       "29  0.007406 -65.53  62.288438  34.776171   9.139979 -30.527581  70.203487   \n",
       "30  0.009480 -12.50  61.326702  33.368683  10.352249 -30.542061  70.204155   \n",
       "31  0.011555  33.17  60.484690  32.339304  10.032896 -34.673407  69.416655   \n",
       "32  0.013690  85.29  60.324456  34.608222   8.981660 -22.554638  72.986165   \n",
       "33  0.015764  37.69  60.182654  32.710273   8.489097 -47.834752  67.457798   \n",
       "\n",
       "          MACD           EMA      kalman  weighted_mean_price_close  \\\n",
       "29  175.002457  23458.921333  152.952256               23753.760000   \n",
       "30  165.649568  23475.958667  153.054765               23735.478333   \n",
       "31  156.059133  23491.593591  153.145906               23726.760000   \n",
       "32  150.867890  23509.536586  153.244258               23720.648333   \n",
       "33  142.407425  23524.159386  153.322722               23744.788333   \n",
       "\n",
       "    weighted_mean_volume_traded  sqrt_ATR  sqrt_ADX  \\\n",
       "29                    82.567046  9.125592  7.892302   \n",
       "30                    72.409438  8.935168  7.831137   \n",
       "31                    57.285328  8.708427  7.777190   \n",
       "32                    50.576388  8.833965  7.766882   \n",
       "33                    77.071568  8.724084  7.757748   \n",
       "\n",
       "    sqrt_weighted_mean_volume_traded  difference1  difference2  \\\n",
       "29                          9.086641        47.77       -22.53   \n",
       "30                          8.509374        40.34         0.00   \n",
       "31                          7.568707        29.46        -4.71   \n",
       "32                          7.111708       103.79        53.68   \n",
       "33                          8.779041        53.37       -34.90   \n",
       "\n",
       "    difference_mean  \n",
       "29           12.620  \n",
       "30           20.170  \n",
       "31           12.375  \n",
       "32           78.735  \n",
       "33            9.235  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price_close_d</th>\n",
       "      <th>WILLR</th>\n",
       "      <th>ROCR</th>\n",
       "      <th>RSI</th>\n",
       "      <th>ATR</th>\n",
       "      <th>MOM</th>\n",
       "      <th>MACD</th>\n",
       "      <th>kalman</th>\n",
       "      <th>sqrt_weighted_mean_volume_traded</th>\n",
       "      <th>difference_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29751</th>\n",
       "      <td>2024-01-04 21:45:00</td>\n",
       "      <td>88979.98</td>\n",
       "      <td>-34.643714</td>\n",
       "      <td>0.107195</td>\n",
       "      <td>61.202499</td>\n",
       "      <td>254.132954</td>\n",
       "      <td>47.64</td>\n",
       "      <td>172.989676</td>\n",
       "      <td>210.187491</td>\n",
       "      <td>16.339968</td>\n",
       "      <td>195.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29752</th>\n",
       "      <td>2024-01-04 22:00:00</td>\n",
       "      <td>89378.20</td>\n",
       "      <td>-10.758157</td>\n",
       "      <td>1.213476</td>\n",
       "      <td>65.115634</td>\n",
       "      <td>251.808458</td>\n",
       "      <td>535.79</td>\n",
       "      <td>193.007338</td>\n",
       "      <td>210.302937</td>\n",
       "      <td>13.082698</td>\n",
       "      <td>208.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29753</th>\n",
       "      <td>2024-01-04 22:15:00</td>\n",
       "      <td>89058.56</td>\n",
       "      <td>-31.669825</td>\n",
       "      <td>1.187202</td>\n",
       "      <td>59.893771</td>\n",
       "      <td>254.180711</td>\n",
       "      <td>522.45</td>\n",
       "      <td>193.742003</td>\n",
       "      <td>210.371217</td>\n",
       "      <td>15.730177</td>\n",
       "      <td>59.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29754</th>\n",
       "      <td>2024-01-04 22:30:00</td>\n",
       "      <td>88884.60</td>\n",
       "      <td>-41.845067</td>\n",
       "      <td>0.911930</td>\n",
       "      <td>57.205040</td>\n",
       "      <td>249.525660</td>\n",
       "      <td>401.62</td>\n",
       "      <td>185.171135</td>\n",
       "      <td>210.413322</td>\n",
       "      <td>17.228622</td>\n",
       "      <td>51.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29755</th>\n",
       "      <td>2024-01-04 22:45:00</td>\n",
       "      <td>88743.32</td>\n",
       "      <td>-50.108795</td>\n",
       "      <td>0.547769</td>\n",
       "      <td>55.043862</td>\n",
       "      <td>248.416684</td>\n",
       "      <td>241.73</td>\n",
       "      <td>170.710755</td>\n",
       "      <td>210.435449</td>\n",
       "      <td>15.178932</td>\n",
       "      <td>82.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29756</th>\n",
       "      <td>2024-01-04 23:00:00</td>\n",
       "      <td>88568.64</td>\n",
       "      <td>-60.326151</td>\n",
       "      <td>-0.233419</td>\n",
       "      <td>52.407547</td>\n",
       "      <td>243.611207</td>\n",
       "      <td>-103.61</td>\n",
       "      <td>150.468682</td>\n",
       "      <td>210.435729</td>\n",
       "      <td>12.967717</td>\n",
       "      <td>45.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29757</th>\n",
       "      <td>2024-01-04 23:15:00</td>\n",
       "      <td>88720.98</td>\n",
       "      <td>-51.415503</td>\n",
       "      <td>0.447071</td>\n",
       "      <td>54.456221</td>\n",
       "      <td>235.581121</td>\n",
       "      <td>197.44</td>\n",
       "      <td>138.971004</td>\n",
       "      <td>210.453198</td>\n",
       "      <td>11.317000</td>\n",
       "      <td>103.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29758</th>\n",
       "      <td>2024-01-04 23:30:00</td>\n",
       "      <td>88412.48</td>\n",
       "      <td>-74.090342</td>\n",
       "      <td>-0.367641</td>\n",
       "      <td>49.782749</td>\n",
       "      <td>233.533183</td>\n",
       "      <td>-163.12</td>\n",
       "      <td>116.074294</td>\n",
       "      <td>210.434144</td>\n",
       "      <td>10.188989</td>\n",
       "      <td>26.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29759</th>\n",
       "      <td>2024-01-04 23:45:00</td>\n",
       "      <td>88386.58</td>\n",
       "      <td>-87.797925</td>\n",
       "      <td>-0.617144</td>\n",
       "      <td>49.399445</td>\n",
       "      <td>226.797242</td>\n",
       "      <td>-274.43</td>\n",
       "      <td>95.779444</td>\n",
       "      <td>210.413973</td>\n",
       "      <td>9.431836</td>\n",
       "      <td>63.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29760</th>\n",
       "      <td>2024-01-05 00:00:00</td>\n",
       "      <td>88506.38</td>\n",
       "      <td>-79.129705</td>\n",
       "      <td>-0.148920</td>\n",
       "      <td>51.268475</td>\n",
       "      <td>217.632439</td>\n",
       "      <td>-66.00</td>\n",
       "      <td>83.565764</td>\n",
       "      <td>210.409260</td>\n",
       "      <td>10.347702</td>\n",
       "      <td>76.320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  price_close_d      WILLR      ROCR        RSI  \\\n",
       "29751 2024-01-04 21:45:00       88979.98 -34.643714  0.107195  61.202499   \n",
       "29752 2024-01-04 22:00:00       89378.20 -10.758157  1.213476  65.115634   \n",
       "29753 2024-01-04 22:15:00       89058.56 -31.669825  1.187202  59.893771   \n",
       "29754 2024-01-04 22:30:00       88884.60 -41.845067  0.911930  57.205040   \n",
       "29755 2024-01-04 22:45:00       88743.32 -50.108795  0.547769  55.043862   \n",
       "29756 2024-01-04 23:00:00       88568.64 -60.326151 -0.233419  52.407547   \n",
       "29757 2024-01-04 23:15:00       88720.98 -51.415503  0.447071  54.456221   \n",
       "29758 2024-01-04 23:30:00       88412.48 -74.090342 -0.367641  49.782749   \n",
       "29759 2024-01-04 23:45:00       88386.58 -87.797925 -0.617144  49.399445   \n",
       "29760 2024-01-05 00:00:00       88506.38 -79.129705 -0.148920  51.268475   \n",
       "\n",
       "              ATR     MOM        MACD      kalman  \\\n",
       "29751  254.132954   47.64  172.989676  210.187491   \n",
       "29752  251.808458  535.79  193.007338  210.302937   \n",
       "29753  254.180711  522.45  193.742003  210.371217   \n",
       "29754  249.525660  401.62  185.171135  210.413322   \n",
       "29755  248.416684  241.73  170.710755  210.435449   \n",
       "29756  243.611207 -103.61  150.468682  210.435729   \n",
       "29757  235.581121  197.44  138.971004  210.453198   \n",
       "29758  233.533183 -163.12  116.074294  210.434144   \n",
       "29759  226.797242 -274.43   95.779444  210.413973   \n",
       "29760  217.632439  -66.00   83.565764  210.409260   \n",
       "\n",
       "       sqrt_weighted_mean_volume_traded  difference_mean  \n",
       "29751                         16.339968          195.035  \n",
       "29752                         13.082698          208.945  \n",
       "29753                         15.730177           59.305  \n",
       "29754                         17.228622           51.165  \n",
       "29755                         15.178932           82.710  \n",
       "29756                         12.967717           45.710  \n",
       "29757                         11.317000          103.685  \n",
       "29758                         10.188989           26.275  \n",
       "29759                          9.431836           63.145  \n",
       "29760                         10.347702           76.320  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df[df['date'] <= '2024-01-05 00:00:00']\n",
    "# Specify the columns you want to keep\n",
    "columns_to_keep = [\n",
    "    'date', \n",
    "    'price_close_d',\n",
    "    'WILLR',\n",
    "    'ROCR',\n",
    "    'RSI',\n",
    "    'ATR',\n",
    "    'MOM',\n",
    "    'MACD',\n",
    "    'kalman',\n",
    "    'sqrt_weighted_mean_volume_traded',\n",
    "    'difference_mean'\n",
    "]\n",
    "\n",
    "# Select only the specified columns\n",
    "filtered_df = filtered_df[columns_to_keep]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "filtered_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['weighted_mean_price_close',\n",
       "  'weighted_mean_volume_traded',\n",
       "  'sqrt_ATR',\n",
       "  'sqrt_ADX',\n",
       "  'sqrt_weighted_mean_volume_traded',\n",
       "  'difference_mean'],\n",
       " ['price_open',\n",
       "  'price_high',\n",
       "  'price_low',\n",
       "  'price_close',\n",
       "  'volume_traded',\n",
       "  'price_close_d'],\n",
       " ['RSI',\n",
       "  'ATR',\n",
       "  'WILLR',\n",
       "  'OBV',\n",
       "  'TRIX',\n",
       "  'MOM',\n",
       "  'MACD',\n",
       "  'ADX',\n",
       "  '+DI',\n",
       "  '-DI',\n",
       "  'EMA',\n",
       "  'ROCR',\n",
       "  'kalman'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features, init_features, ta_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RSI</th>\n",
       "      <th>ATR</th>\n",
       "      <th>difference_mean</th>\n",
       "      <th>ROCR</th>\n",
       "      <th>WILLR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>70.203487</td>\n",
       "      <td>83.276438</td>\n",
       "      <td>12.620</td>\n",
       "      <td>-0.275469</td>\n",
       "      <td>-30.527581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>70.204155</td>\n",
       "      <td>79.837228</td>\n",
       "      <td>20.170</td>\n",
       "      <td>-0.052664</td>\n",
       "      <td>-30.542061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>69.416655</td>\n",
       "      <td>75.836701</td>\n",
       "      <td>12.375</td>\n",
       "      <td>0.140046</td>\n",
       "      <td>-34.673407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>72.986165</td>\n",
       "      <td>78.038932</td>\n",
       "      <td>78.735</td>\n",
       "      <td>0.360110</td>\n",
       "      <td>-22.554638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>67.457798</td>\n",
       "      <td>76.109640</td>\n",
       "      <td>9.235</td>\n",
       "      <td>0.159040</td>\n",
       "      <td>-47.834752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43480</th>\n",
       "      <td>42.034091</td>\n",
       "      <td>142.147142</td>\n",
       "      <td>116.810</td>\n",
       "      <td>-0.392352</td>\n",
       "      <td>-38.856918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43481</th>\n",
       "      <td>45.540077</td>\n",
       "      <td>139.850917</td>\n",
       "      <td>86.875</td>\n",
       "      <td>-0.321339</td>\n",
       "      <td>-30.600760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43482</th>\n",
       "      <td>44.889071</td>\n",
       "      <td>135.850852</td>\n",
       "      <td>33.960</td>\n",
       "      <td>-0.258071</td>\n",
       "      <td>-31.674290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43483</th>\n",
       "      <td>40.449974</td>\n",
       "      <td>133.716505</td>\n",
       "      <td>0.405</td>\n",
       "      <td>-0.307605</td>\n",
       "      <td>-44.836505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43484</th>\n",
       "      <td>38.180960</td>\n",
       "      <td>129.676755</td>\n",
       "      <td>9.795</td>\n",
       "      <td>-0.317195</td>\n",
       "      <td>-52.243627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43451 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             RSI         ATR  difference_mean      ROCR      WILLR\n",
       "29     70.203487   83.276438           12.620 -0.275469 -30.527581\n",
       "30     70.204155   79.837228           20.170 -0.052664 -30.542061\n",
       "31     69.416655   75.836701           12.375  0.140046 -34.673407\n",
       "32     72.986165   78.038932           78.735  0.360110 -22.554638\n",
       "33     67.457798   76.109640            9.235  0.159040 -47.834752\n",
       "...          ...         ...              ...       ...        ...\n",
       "43480  42.034091  142.147142          116.810 -0.392352 -38.856918\n",
       "43481  45.540077  139.850917           86.875 -0.321339 -30.600760\n",
       "43482  44.889071  135.850852           33.960 -0.258071 -31.674290\n",
       "43483  40.449974  133.716505            0.405 -0.307605 -44.836505\n",
       "43484  38.180960  129.676755            9.795 -0.317195 -52.243627\n",
       "\n",
       "[43451 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = []\n",
    "features += init_features\n",
    "features +=ta_features\n",
    "features += new_features  \n",
    "\n",
    "# Remove specific items from features\n",
    "features_to_remove = [\"price_open\", \"price_high\", \"price_low\", \"volume_traded\", \"price_close\", \"price_close_d\", \"weighted_mean_price_close\",\n",
    "                      \"sqrt_ATR\" ,\"weighted_mean_volume_traded\", \"ADX\", \"kalman\", \"OBV\", \"TRIX\", \"sqrt_ADX\", \"sqrt_weighted_mean_volume_traded\",\n",
    "                       \"+DI\", \"-DI\", \"EMA\", \"MOM\", \"MACD\"]\n",
    "\n",
    "features = [feature for feature in features if feature not in features_to_remove]\n",
    "\n",
    "features = ['RSI', 'ATR', 'difference_mean', 'ROCR',  'WILLR',  ]\n",
    "df[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Seperate labels from features in the training set\n",
    "- Split training set as training and validation set\n",
    "\n",
    "\n",
    "## Attention : One should not split the data randomly but sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (34760, 5)\n",
      "Validation Data Shape: (8691, 5)\n",
      "Training Label Shape: (34760,)\n",
      "Validation Label Shape: (8691,)\n"
     ]
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "train_index = int(0.8 * len(X))\n",
    "\n",
    "# Split data\n",
    "X_train, X_test = X[:train_index], X[train_index:]\n",
    "y_train, y_test = y[:train_index], y[train_index:]\n",
    "\n",
    "print('Training Data Shape:', X_train.shape)\n",
    "print('Validation Data Shape:', X_test.shape)\n",
    "print('Training Label Shape:', y_train.shape)\n",
    "print('Validation Label Shape:', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a baseline metric\n",
    "\n",
    "Before diving deep into the ML classification algorithms, we are calculated a common sense baseline. A common sense baseline is defined as how a person has a knowledge in that field would solve the problem without using any data science tricks. It can be a dummy or simple algorithm, consisting of few lines of code, to use as a baseline metric.\n",
    "\n",
    "We will use as a metric of accuracy which is percentage of correctly predicted trees among the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our dummy algorithm classified 0.49 of the of the trees correctly\n"
     ]
    }
   ],
   "source": [
    "# Create dummy classifer\n",
    "dummy = DummyClassifier(strategy='stratified', random_state=42)\n",
    "\n",
    "# train the model\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "# Get accuracy score\n",
    "baseline_accuracy = dummy.score(X_test, y_test)\n",
    "print(\"Our dummy algorithm classified {:0.2f} of the of the trees correctly\".format(baseline_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing \n",
    "\n",
    "#### Encoding Variables (Standard Scaling)\n",
    "\n",
    "Feature scaling through standardization (or Z-score normalization) can be an important preprocessing step for many machine learning algorithms. Standardization involves rescaling the features such that they have the properties of a standard normal distribution with a mean of zero and a standard deviation of one. Many algorithms (such as SVM, K-nearest neighbors, and logistic regression) require features to be normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Standardize numerical feature\\ncolumns = X_train.columns\\n# Create scaler\\nscaler = StandardScaler()\\n\\n# After scaling\\nX_train = pd.DataFrame(scaler.fit_transform(X_train), columns=columns)\\nX_train = pd.DataFrame(scaler.transform(X_train), columns=columns)'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Standardize numerical feature\n",
    "columns = X_train.columns\n",
    "# Create scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# After scaling\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=columns)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train), columns=columns)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Model Building and Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier\n",
    "\n",
    "models = {\n",
    "    #\"LR\": LogisticRegression(max_iter=50, random_state=42, penalty='l2', solver='liblinear', C=4/5),\n",
    "    \"XGB\": XGBClassifier(n_estimators=400, random_state=42),\n",
    "    \"ET\": ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
    "    'gbc': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Base models\n",
    "base_models = [\n",
    "    ('xgb', XGBClassifier(n_estimators=400, random_state=42)),\n",
    "    ('et', ExtraTreesClassifier(n_estimators=100, random_state=42)),\n",
    "    ('gbc', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "\n",
    "    ]\n",
    "\n",
    "# Meta-classifier\n",
    "meta_classifier = LogisticRegression()\n",
    "\n",
    "# Stacking classifier\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_classifier, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for training and evaluating models\n",
    "def train_and_evaluate_model(model, X_train, X_test, y_train, y_test, plot=False):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    " \n",
    "    # Calcul de la matrice de confusion\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Calcul de l'accuracy par classe\n",
    "    class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
    "    \n",
    "    # Affichage de l'accuracy pour chaque classe\n",
    "    for i, class_label in enumerate(model.classes_):\n",
    "        print(f\"Accuracy for class {class_label}: {class_accuracies[i]:.4f}\")\n",
    "\n",
    "    if plot: \n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "\n",
    "        # Affichage de la matrice de confusion\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "        disp.plot()\n",
    "\n",
    "    \n",
    "def perform_nested_cross_validation(model, X, y, outer_cv=5, inner_cv=3):\n",
    "    outer_scores = []\n",
    "    tscv = TimeSeriesSplit(n_splits=outer_cv)\n",
    "    \n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train_cv, X_test_cv = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train_cv, y_test_cv = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        inner_scores = cross_val_score(model, X_train_cv, y_train_cv, cv=TimeSeriesSplit(n_splits=inner_cv), scoring='accuracy')\n",
    "        outer_scores.append(inner_scores.mean())\n",
    "    \n",
    "    print(\"Nested Cross-Validation Scores:\", outer_scores)\n",
    "    print(\"Mean Nested CV Accuracy:\", np.mean(outer_scores))\n",
    "    print(\"Standard Deviation:\", np.std(outer_scores))\n",
    "\n",
    "\n",
    "\n",
    "# Define function for cross-validation\n",
    "def perform_cross_validation(model, X, y, cv=5):\n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "    # Print cross-validation scores\n",
    "    print(\"Cross-Validation Scores:\", scores)\n",
    "    print(\"Mean Accuracy:\", scores.mean())\n",
    "    print(\"Standard Deviation:\", scores.std())\n",
    "\n",
    "\n",
    "# Main testing function\n",
    "def testing(models, cross_val=False, nested=False):\n",
    "    # Train and evaluate each model\n",
    "    for name, model in models.items():\n",
    "        print(\"-\" * 50)\n",
    "        print(\"Training and evaluating\", name)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        train_and_evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "        # Cross-validation\n",
    "        if cross_val:\n",
    "            print(\"-\" * 50)\n",
    "            print(\"Performing cross-validation for\", name)\n",
    "            perform_cross_validation(model=model, X=X_train, y=y_train)\n",
    "            print(\"=\" * 70)\n",
    "\n",
    "        # Nested Cross-validation\n",
    "        if nested:\n",
    "            print(\"-\" * 50)\n",
    "            print(\"Performing nested cross-validation for\", name)\n",
    "            perform_nested_cross_validation(model=model, X=X_train, y=y_train)\n",
    "            print(\"=\" * 70)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Training and evaluating XGB\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.5269\n",
      "Accuracy for class 0: 0.5268\n",
      "Accuracy for class 1: 0.5269\n",
      "--------------------------------------------------\n",
      "Training and evaluating ET\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.5314\n",
      "Accuracy for class 0: 0.5412\n",
      "Accuracy for class 1: 0.5213\n",
      "--------------------------------------------------\n",
      "Training and evaluating gbc\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.5430\n",
      "Accuracy for class 0: 0.5075\n",
      "Accuracy for class 1: 0.5793\n"
     ]
    }
   ],
   "source": [
    "testing(models, cross_val=False, nested=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Training and evaluating Stacking Classifier\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.5448\n",
      "Accuracy for class 0: 0.5225\n",
      "Accuracy for class 1: 0.5676\n"
     ]
    }
   ],
   "source": [
    "# Train the stacking classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation data\n",
    "y_pred_val = stacking_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_val)\n",
    "accuracy_class_0 = accuracy_score(y_test[y_test == 0], y_pred_val[y_test == 0])\n",
    "accuracy_class_1 = accuracy_score(y_test[y_test == 1], y_pred_val[y_test == 1])\n",
    "\n",
    "# Print results\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"Training and evaluating Stacking Classifier\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Accuracy for class 0: {accuracy_class_0:.4f}')\n",
    "print(f'Accuracy for class 1: {accuracy_class_1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'LR'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Extract intercept and coefficients\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m intercept \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mintercept_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      6\u001b[0m coefficients \u001b[38;5;241m=\u001b[39m models[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcoef_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create a DataFrame to display the intercept and coefficients\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'LR'"
     ]
    }
   ],
   "source": [
    "# Assuming the features are in the same order as in your training set\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Extract intercept and coefficients\n",
    "intercept = models['LR'].intercept_[0]\n",
    "coefficients = models['LR'].coef_[0]\n",
    "\n",
    "# Create a DataFrame to display the intercept and coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': ['Intercept'] + list(feature_names),\n",
    "    'Coefficient': [intercept] + list(coefficients)\n",
    "})\n",
    "\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 - Stacking\n",
    "UtilisÃ© 4 classifier (Logistic, XGB, ExtraTrees et KNN) avec un poids pour les + performants et faire un softmax des 4 prÃ©dictions\n",
    "\n",
    "- \"LR\": LogisticRegression(max_iter=50, random_state=42, penalty='l2', solver='liblinear', C=2/3 )\n",
    "   - Features : price_close_d\tWILLR\tROCR\tRSI\tATR\tMOM\tMACD\tkalman\tsqrt_weighted_mean_volume_traded\tdifference_mean\n",
    "\n",
    "\n",
    "- \"Stacking\" : # Base models\n",
    "base_models = [\n",
    "    ('xgb', XGBClassifier(n_estimators=400, random_state=42)),\n",
    "    ('et', ExtraTreesClassifier(n_estimators=100, random_state=42)),\n",
    "    ('gbc', GradientBoostingClassifier(n_estimators=100, random_state=42))]\n",
    "\n",
    "\n",
    "    \n",
    "RSI\tATR\tdifference_mean\tROCR\tWILLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ET</th>\n",
       "      <th>XGB</th>\n",
       "      <th>GB</th>\n",
       "      <th>STK</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43401</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43402</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43403</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43404</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43405</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43406</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43407</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43408</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43409</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43410</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43411</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43412</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43413</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43414</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43415</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43416</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43417</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43418</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43419</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43420</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43421</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43422</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43423</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43424</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43425</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43426</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43427</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43428</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43429</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43430</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43431</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43432</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43433</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43434</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43435</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43436</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43437</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43438</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43439</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43440</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43441</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43442</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43443</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43444</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43445</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43446</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43447</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43448</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43449</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43450</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ET  XGB  GB  STK  Actual\n",
       "43401   1    1   0    0       0\n",
       "43402   0    0   0    0       0\n",
       "43403   0    0   0    0       0\n",
       "43404   1    1   1    1       0\n",
       "43405   1    1   1    1       0\n",
       "43406   0    0   1    0       0\n",
       "43407   0    0   0    0       0\n",
       "43408   1    0   1    1       1\n",
       "43409   1    0   1    1       0\n",
       "43410   1    1   1    1       1\n",
       "43411   1    0   1    1       1\n",
       "43412   0    1   1    1       1\n",
       "43413   1    1   0    0       1\n",
       "43414   1    1   0    0       1\n",
       "43415   1    1   1    1       1\n",
       "43416   1    1   0    0       1\n",
       "43417   1    1   0    0       0\n",
       "43418   0    1   0    0       0\n",
       "43419   0    0   0    0       0\n",
       "43420   1    1   1    1       0\n",
       "43421   1    1   1    1       1\n",
       "43422   1    1   1    1       0\n",
       "43423   1    1   1    1       1\n",
       "43424   0    0   1    1       0\n",
       "43425   1    0   1    1       1\n",
       "43426   1    1   1    1       0\n",
       "43427   1    1   1    1       0\n",
       "43428   1    0   1    1       0\n",
       "43429   0    0   1    1       0\n",
       "43430   0    0   1    1       1\n",
       "43431   1    1   1    1       1\n",
       "43432   1    1   1    1       1\n",
       "43433   0    0   1    1       1\n",
       "43434   0    0   1    1       1\n",
       "43435   1    1   1    1       1\n",
       "43436   1    1   1    1       0\n",
       "43437   1    0   1    1       0\n",
       "43438   1    0   1    1       0\n",
       "43439   0    1   1    1       0\n",
       "43440   1    1   1    1       0\n",
       "43441   0    0   1    1       0\n",
       "43442   1    0   1    1       0\n",
       "43443   1    1   1    1       1\n",
       "43444   1    0   1    1       1\n",
       "43445   1    1   1    1       1\n",
       "43446   1    1   1    1       0\n",
       "43447   0    0   1    1       0\n",
       "43448   0    1   1    1       0\n",
       "43449   1    1   1    1       0\n",
       "43450   1    1   1    1       1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#proba_logistic = models['LR'].predict_proba(X_test)\n",
    "#predicted_logistic= models['LR'].predict(X_test)\n",
    "predicted_extra = models['ET'].predict(X_test)\n",
    "predicted_gbc = models['gbc'].predict(X_test)\n",
    "predicted_xgb = models['XGB'].predict(X_test)\n",
    "predicted_stacking = stacking_clf.predict(X_test)\n",
    "\n",
    "# Creating a DataFrame to compare actual and predicted values\n",
    "comparison_df = pd.DataFrame({\n",
    "    #'Proba 0': proba_logistic[:, 0],\n",
    "    #'Proba 1': proba_logistic[:, 1],\n",
    "    #'LR': predicted_logistic,\n",
    "    'ET': predicted_extra,\n",
    "    'XGB': predicted_xgb,  \n",
    "    'GB': predicted_gbc,  \n",
    "    'STK' :  predicted_stacking, \n",
    "    'Actual': y_test,\n",
    "\n",
    "})\n",
    "comparison_df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690030\n",
      "         Iterations 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>P-value</th>\n",
       "      <th>Recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RSI</td>\n",
       "      <td>-0.005202</td>\n",
       "      <td>7.400893e-22</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATR</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>2.757345e-12</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>difference_mean</td>\n",
       "      <td>-0.000726</td>\n",
       "      <td>1.065345e-03</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROCR</td>\n",
       "      <td>-0.010047</td>\n",
       "      <td>6.330637e-01</td>\n",
       "      <td>Consider Removing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WILLR</td>\n",
       "      <td>-0.003081</td>\n",
       "      <td>3.266800e-12</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature  Coefficient       P-value     Recommendation\n",
       "0              RSI    -0.005202  7.400893e-22               Keep\n",
       "1              ATR     0.001480  2.757345e-12               Keep\n",
       "2  difference_mean    -0.000726  1.065345e-03               Keep\n",
       "3             ROCR    -0.010047  6.330637e-01  Consider Removing\n",
       "4            WILLR    -0.003081  3.266800e-12               Keep"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Define the penalized logistic regression model with L2 regularization\n",
    "logit_model = sm.Logit(y_train, X_train)\n",
    "\n",
    "# Fit the model with L2 regularization, using L-BFGS-B solver and max_iter=2000\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Extracting coefficients, p-values, and feature names\n",
    "coefficients = result.params\n",
    "p_values = result.pvalues\n",
    "confidence_intervals = result.conf_int()\n",
    "\n",
    "# Creating a DataFrame to display feature names, coefficients, p-values, and confidence intervals\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': list(X_train.columns),\n",
    "    'Coefficient': coefficients.values,\n",
    "    'P-value': p_values.values,\n",
    "    'Recommendation': ['Keep' if p < 0.05 else 'Consider Removing' for p in p_values]\n",
    "})\n",
    "\n",
    "coef_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming `features` is a list of your feature names and each model in `models` is a fitted model\n",
    "feature_importances = pd.DataFrame({\"ET\": models[\"ET\"].feature_importances_ }, index=features)\n",
    "\n",
    "# Convert the DataFrame to have features as columns and models as rows\n",
    "feature_importances = feature_importances.T\n",
    "\n",
    "# Now you can sort the mean feature importances for each feature across models\n",
    "sorted_features = feature_importances.mean().sort_values(ascending=False).index.tolist()\n",
    "\n",
    "sns.barplot(data=feature_importances, orient='h', order=sorted_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Coefficient (coef): Indicates the direction and magnitude of the effect of each feature on the log-odds of the target variable.\n",
    "- Standard Error (std err): Measures the variability in the coefficient estimates.\n",
    "- Z-value (z): The coefficient divided by its standard error, used to test the null hypothesis that the coefficient is zero.\n",
    "- P-value (P>|z|): Indicates the probability of observing the given result, assuming the null hypothesis is true. A small p-value (typically < 0.05) indicates that you can reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6- Perform Hyperparameter Tuning on the Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform hyperparameter tuning, we are going to define set of parameters and RandomizedSearchCV will look for the best combination with cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
    "    \n",
    "    # Check if both class accuracies are above 51%\n",
    "    if class_accuracies[0] > 0.51 and class_accuracies[1] > 0.51:\n",
    "        return accuracy_score(y_true, y_pred)  # Return overall accuracy if condition is met\n",
    "    else:\n",
    "        return 0  # Return 0 if the condition is not met\n",
    "\n",
    "# Create the custom scorer\n",
    "custom_scorer = make_scorer(custom_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid for Logistic Regression\n",
    "hyperparameter_grid = {\n",
    "    'logistic__penalty': ['l2'],  # Regularization penalty\n",
    "    'logistic__C': [1/4, 1/2, 1, 2/3, 3/4],  # Inverse of regularization strength\n",
    "    'logistic__solver': ['liblinear'],  # Solvers 'saga'\n",
    "    'logistic__max_iter': [50, 80, 100, 200, 300, 00]   # Maximum number of iterations\n",
    "}\n",
    "\n",
    "# Set up the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('logistic', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Randomized search with cross-validation\n",
    "grid_search  = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=hyperparameter_grid,\n",
    "    cv=5,  # Cross-validation splitting strategy\n",
    "    scoring=custom_scorer,  # Scoring metric\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'xgb__max_depth': [3, 5],\n",
    "    'knn__kneighborsclassifier__n_neighbors': [3, 5, 7],\n",
    "    'knn__kneighborsclassifier__weights': ['uniform', 'distance'],\n",
    "    'gbc__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'final_estimator__C': [ 1.0, 10.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=stacking_clf, param_grid=param_grid, cv=2, n_jobs=-1, scoring='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'knn' for estimator StackingClassifier(cv=5,\n                   estimators=[('xgb',\n                                XGBClassifier(base_score=None, booster=None,\n                                              callbacks=None,\n                                              colsample_bylevel=None,\n                                              colsample_bynode=None,\n                                              colsample_bytree=None,\n                                              device=None,\n                                              early_stopping_rounds=None,\n                                              enable_categorical=False,\n                                              eval_metric=None,\n                                              feature_types=None, gamma=None,\n                                              grow_policy=None,\n                                              importance_type=None,\n                                              interaction_constraints=None,\n                                              lear...\n                                              max_cat_to_onehot=None,\n                                              max_delta_step=None,\n                                              max_depth=None, max_leaves=None,\n                                              min_child_weight=None,\n                                              missing=nan,\n                                              monotone_constraints=None,\n                                              multi_strategy=None,\n                                              n_estimators=400, n_jobs=None,\n                                              num_parallel_tree=None,\n                                              random_state=42, ...)),\n                               ('et', ExtraTreesClassifier(random_state=42)),\n                               ('gbc',\n                                GradientBoostingClassifier(random_state=42))],\n                   final_estimator=LogisticRegression()). Valid parameters are: ['cv', 'estimators', 'final_estimator', 'n_jobs', 'passthrough', 'stack_method', 'verbose'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 129, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 883, in _fit_and_score\n    estimator = estimator.set_params(**clone(parameters, safe=False))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 266, in set_params\n    super()._set_params(\"estimators\", **params)\n  File \"c:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 71, in _set_params\n    super().set_params(**params)\n  File \"c:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 279, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'knn' for estimator StackingClassifier(cv=5,\n                   estimators=[('xgb',\n                                XGBClassifier(base_score=None, booster=None,\n                                              callbacks=None,\n                                              colsample_bylevel=None,\n                                              colsample_bynode=None,\n                                              colsample_bytree=None,\n                                              device=None,\n                                              early_stopping_rounds=None,\n                                              enable_categorical=False,\n                                              eval_metric=None,\n                                              feature_types=None, gamma=None,\n                                              grow_policy=None,\n                                              importance_type=None,\n                                              interaction_constraints=None,\n                                              lear...\n                                              max_cat_to_onehot=None,\n                                              max_delta_step=None,\n                                              max_depth=None, max_leaves=None,\n                                              min_child_weight=None,\n                                              missing=nan,\n                                              monotone_constraints=None,\n                                              multi_strategy=None,\n                                              n_estimators=400, n_jobs=None,\n                                              num_parallel_tree=None,\n                                              random_state=42, ...)),\n                               ('et', ExtraTreesClassifier(random_state=42)),\n                               ('gbc',\n                                GradientBoostingClassifier(random_state=42))],\n                   final_estimator=LogisticRegression()). Valid parameters are: ['cv', 'estimators', 'final_estimator', 'n_jobs', 'passthrough', 'stack_method', 'verbose'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[849], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fit the random search model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Print the best parameters and the best score\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters found: \u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'knn' for estimator StackingClassifier(cv=5,\n                   estimators=[('xgb',\n                                XGBClassifier(base_score=None, booster=None,\n                                              callbacks=None,\n                                              colsample_bylevel=None,\n                                              colsample_bynode=None,\n                                              colsample_bytree=None,\n                                              device=None,\n                                              early_stopping_rounds=None,\n                                              enable_categorical=False,\n                                              eval_metric=None,\n                                              feature_types=None, gamma=None,\n                                              grow_policy=None,\n                                              importance_type=None,\n                                              interaction_constraints=None,\n                                              lear...\n                                              max_cat_to_onehot=None,\n                                              max_delta_step=None,\n                                              max_depth=None, max_leaves=None,\n                                              min_child_weight=None,\n                                              missing=nan,\n                                              monotone_constraints=None,\n                                              multi_strategy=None,\n                                              n_estimators=400, n_jobs=None,\n                                              num_parallel_tree=None,\n                                              random_state=42, ...)),\n                               ('et', ExtraTreesClassifier(random_state=42)),\n                               ('gbc',\n                                GradientBoostingClassifier(random_state=42))],\n                   final_estimator=LogisticRegression()). Valid parameters are: ['cv', 'estimators', 'final_estimator', 'n_jobs', 'passthrough', 'stack_method', 'verbose']."
     ]
    }
   ],
   "source": [
    "# Fit the random search model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Best Model Testing\n",
    "\n",
    "Also On Simulated Data ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Test with Tuned Hyperparameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5448\n",
      "Accuracy for class 0: 0.5225\n",
      "Accuracy for class 1: 0.5676\n",
      "Confusion Matrix:\n",
      "[[2297 2099]\n",
      " [1857 2438]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on the test set using the best estimator\n",
    "\n",
    "# Predict on validation data\n",
    "best_model = stacking_clf\n",
    "train_and_evaluate_model(best_model, X_train, X_test, y_train, y_test, plot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9- Walk Forward Validation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=1.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=0.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=2.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=1.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=0.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n",
      "Direction - predicted=1.0, actual=2.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[154], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_test)):\n\u001b[0;32m      9\u001b[0m     model \u001b[38;5;241m=\u001b[39m best_model\n\u001b[1;32m---> 10\u001b[0m     model_fit \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_rolling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_rolling\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Fit model on expanding window\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Expanding training set with the new observation\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     new_X \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39miloc[t:t\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Ensure DataFrame format by slicing\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:475\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    474\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 475\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1221\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1216\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1217\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m > 1 does not have any effect when\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1218\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is set to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1219\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs))\n\u001b[0;32m   1220\u001b[0m         )\n\u001b[1;32m-> 1221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43m_fit_liblinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1231\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1232\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1234\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1235\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   1238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\SolalDanan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:1217\u001b[0m, in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m   1214\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m   1216\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n\u001b[1;32m-> 1217\u001b[0m raw_coef_, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43mliblinear\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_wrap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_ind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrnd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;66;03m# Regarding rnd.randint(..) in the above signature:\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;66;03m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;66;03m# on 32-bit platforms, we can't get to the UINT_MAX limit that\u001b[39;00m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;66;03m# srand supports\u001b[39;00m\n\u001b[0;32m   1235\u001b[0m n_iter_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n_iter_)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train_rolling = X_train.copy()\n",
    "y_train_rolling = y_train.copy()\n",
    "actu_directions = []\n",
    "pred_directions = []\n",
    "predictions = []\n",
    "\n",
    "# Assuming 'test' is your test set, use X_test and y_test for consistency\n",
    "for t in range(len(X_test)):\n",
    "    model = best_model\n",
    "    model_fit = model.fit(X_train_rolling, y_train_rolling)  # Fit model on expanding window\n",
    "\n",
    "    # Expanding training set with the new observation\n",
    "    new_X = X_test.iloc[t:t+1]  # Ensure DataFrame format by slicing\n",
    "    y_pred = model.predict(new_X)  # Ensure new_X has correct column names and order\n",
    "    predictions.append(y_pred[0])\n",
    "\n",
    "    X_train_rolling = pd.concat([X_train_rolling, new_X], ignore_index=True)\n",
    "    y_train_rolling = pd.concat([y_train_rolling, pd.Series([y_test.iloc[t]], index=[X_train_rolling.index[-1]])])\n",
    "\n",
    "    pred_direction = predictions[-1]\n",
    "    actu_direction = y_test.iloc[t]\n",
    "        \n",
    "    pred_directions.append(pred_direction)\n",
    "    actu_directions.append(actu_direction)\n",
    "\n",
    "    print(f'Direction - predicted={pred_direction}, actual={actu_direction}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[853], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate evaluation metrics\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, \u001b[43mpredictions\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Calcul de la matrice de confusion\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calcul de la matrice de confusion\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Calcul de l'accuracy par classe\n",
    "class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "# Affichage de l'accuracy pour chaque classe\n",
    "for i, class_label in enumerate(model.classes_):\n",
    "    print(f\"Accuracy for class {class_label}: {class_accuracies[i]:.2f}\")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Affichage de la matrice de confusion\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "\n",
    "# GÃ©nÃ©ration du rapport de classification\n",
    "report = classification_report(y_test, predictions, target_names=[str(cls) for cls in model.classes_])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 - Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/SolalDanan/Trading Signal/stacking_model.joblib']"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(stacking_clf, 'C:/Users/SolalDanan/Trading Signal/stacking_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;xgb&#x27;,\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              lear...\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=400, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=42, ...)),\n",
       "                               (&#x27;et&#x27;, ExtraTreesClassifier(random_state=42)),\n",
       "                               (&#x27;gbc&#x27;,\n",
       "                                GradientBoostingClassifier(random_state=42))],\n",
       "                   final_estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StackingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.StackingClassifier.html\">?<span>Documentation for StackingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;xgb&#x27;,\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              lear...\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=400, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=42, ...)),\n",
       "                               (&#x27;et&#x27;, ExtraTreesClassifier(random_state=42)),\n",
       "                               (&#x27;gbc&#x27;,\n",
       "                                GradientBoostingClassifier(random_state=42))],\n",
       "                   final_estimator=LogisticRegression())</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=400, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>et</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;ExtraTreesClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\">?<span>Documentation for ExtraTreesClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ExtraTreesClassifier(random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>gbc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GradientBoostingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier(random_state=42)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('xgb',\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              lear...\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=400, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=42, ...)),\n",
       "                               ('et', ExtraTreesClassifier(random_state=42)),\n",
       "                               ('gbc',\n",
       "                                GradientBoostingClassifier(random_state=42))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = joblib.load('C:/Users/SolalDanan/Trading Signal/stacking_model.joblib')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
